{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eeabcb29-28e6-420f-a3f0-05186d012e92",
   "metadata": {},
   "source": [
    "# Capstone Milestone 3: Federal Funds Rate Regression Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee533e5-eee2-4493-a108-6a4723d8304a",
   "metadata": {},
   "source": [
    "In this project we will construct models for the Federal Funds Effective Rate, which we will just call the Federal Funds Rate (FFR). This is a rate determined by the market, similar to stock prices in the stock market. The FFR is a key tool used in monetary policy that influences economic activity. The Federal Reserve sets a Target for the FFR, then performs operations such as trading bonds to adjust the FFR, bringing it closer to the Target. Predicting the FFR benefits educators, economists, investors, financial institutions, and policy planners.\n",
    "\n",
    "This project aims to first reproduce regression models predicting the FFR using Taylor’s Rule, a policy guideline by John Taylor from Stanford in 1993 and a modification of this used by researcher Alper D. Karakas, the equations of which are derived in Karkas’ (2023) paper, “Reevaluating the Taylor Rule with Machine Learning.”\n",
    "\n",
    "We will then attempt to construct other models by adding the Target and Unemployment Rate to the Taylor Model to see if the addition of new features can improve the performance of regression models in predicting the Federal Funds Effective Rate. We choose to build off the Taylor Model as this is the foundational model and Karakas (2023) found little difference in performance between this model and their model.\n",
    "\n",
    "We will also check the assumptions of regression for each model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92066e7f-82c8-4586-a649-17572cc51223",
   "metadata": {},
   "source": [
    "## Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fd50c9-b2d6-408f-a6a5-22cacb03d29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler, MinMaxScaler\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.stats.diagnostic import het_breuschpagan, linear_rainbow\n",
    "from statsmodels.stats.stattools import durbin_watson, jarque_bera\n",
    "from scipy.stats.mstats import winsorize\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243dc19e-45af-4172-89c8-9f0fa9dbfc75",
   "metadata": {},
   "source": [
    "## Defining Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7737c604-52af-4f69-bd08-dfb747919355",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_ols_model(X, y, model_name):\n",
    "    \"\"\"Fits an OLS Regression model for the given variables and returns predictions.\"\"\"\n",
    "    # Fit the model\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    \n",
    "    # Get predictions\n",
    "    y_pred = model.predict(X)\n",
    "    return model, y_pred\n",
    "\n",
    "\n",
    "def calculate_vif(X, model_name):\n",
    "    \"\"\"Calculates Variance Inflation Factors (VIFs).\"\"\"\n",
    "    \n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"Feature\"] = X.columns\n",
    "    vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "    return vif_data\n",
    "\n",
    "\n",
    "def error_metrics(y, y_pred):\n",
    "    \"\"\"Computes error metrics.\"\"\"\n",
    "    \n",
    "    mse = round(mean_squared_error(y, y_pred), 3)\n",
    "    rmse = round(np.sqrt(mse), 3)\n",
    "    mae = round(mean_absolute_error(y, y_pred), 3)\n",
    "    mpe = round(np.mean((y - y_pred) / y) * 100, 3)\n",
    "    mape = round(np.mean(np.abs((y - y_pred) / y)) * 100, 3)\n",
    "    r2 = r2_score(y, y_pred)\n",
    "    return {\n",
    "        \"Mean Squared Error\": mse,\n",
    "        \"Root Mean Squared Error\": rmse,\n",
    "        \"Mean Absolute Error\": mae,\n",
    "        \"Mean Percentage Error\": mpe,\n",
    "        \"Mean Absolute Percentage Error\": mape,\n",
    "        \"R-Squared\": r2\n",
    "    }\n",
    "\n",
    "\n",
    "def fit_nn_model(X, y, model_name):\n",
    "    \"\"\"Fits a Neural Network model for the given variables and returns predictions and model.\"\"\"\n",
    "    # Set the input dimension\n",
    "    input_dim = X.shape[1]\n",
    "\n",
    "    # Define the neural network with an explicit Input layer\n",
    "    model = Sequential([\n",
    "        Input(shape=(input_dim,)),\n",
    "        Dense(20, activation='relu'),\n",
    "        Dense(1, activation='linear')\n",
    "    ])\n",
    "\n",
    "    # Compile the model and fit\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "    model.fit(X, y, epochs=50, batch_size=5, verbose=0)\n",
    "\n",
    "    # Get predictions\n",
    "    y_pred = model.predict(X).flatten()\n",
    "    return model, y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a862d67-1d82-4641-a885-892e996d9c38",
   "metadata": {},
   "source": [
    "## Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f881e2-9e33-46dd-a5f8-f321480c87ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary with datasets and their URLs\n",
    "datasets = {\n",
    "    \"ffer\": \"https://raw.githubusercontent.com/nvpham12/Capstone-Project/refs/heads/main/FFER.csv\",\n",
    "    \"pgdp\": \"https://raw.githubusercontent.com/nvpham12/Capstone-Project/refs/heads/main/PGDP.csv\",\n",
    "    \"rgdp\": \"https://raw.githubusercontent.com/nvpham12/Capstone-Project/refs/heads/main/RGDP.csv\",\n",
    "    \"cpi\": \"https://raw.githubusercontent.com/nvpham12/Capstone-Project/refs/heads/main/CPI.csv\",\n",
    "    \"fftr_lower\": \"https://raw.githubusercontent.com/nvpham12/Capstone-Project/refs/heads/main/FFTR_lower.csv\",\n",
    "    \"fftr_upper\": \"https://raw.githubusercontent.com/nvpham12/Capstone-Project/refs/heads/main/FFTR_upper.csv\",\n",
    "    \"fftr_old\": \"https://raw.githubusercontent.com/nvpham12/Capstone-Project/refs/heads/main/FFTR_old.csv\",\n",
    "    \"unrate\": \"https://raw.githubusercontent.com/nvpham12/Capstone-Project/refs/heads/main/UNRATE.csv\"\n",
    "}\n",
    "\n",
    "# Iterate and load datasets\n",
    "for name, url in datasets.items():\n",
    "    globals()[name] = pd.read_csv(url, parse_dates=[\"observation_date\"])\n",
    "    print(f\"{name} dataset loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84632386-a1a4-44b9-9860-182c8e3342bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the dataset names in the dictionary\n",
    "for name in datasets.keys():\n",
    "    # Access the DataFrame using globals()\n",
    "    dataframe = globals()[name]\n",
    "    duplicates = dataframe[dataframe.duplicated(keep=False)] \n",
    "    if not duplicates.empty:\n",
    "        print(f\"'{name}' has {len(duplicates)} duplicate rows:\")\n",
    "        print(duplicates)\n",
    "    else:\n",
    "        print(f\"'{name}' has no duplicate rows.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc82f5f8-a302-4205-a9cd-3c959c718203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data for CPI can be used to find inflation rates. \n",
    "# This is done to obtain a seasonally adjusted inflation dataset that isn't available on FRED.\n",
    "inflation = pd.DataFrame()\n",
    "inflation[\"observation_date\"] = cpi[\"observation_date\"] \n",
    "inflation[\"Inflation\"] = cpi[\"CPIAUCSL\"].pct_change(periods=12) * 100\n",
    "inflation.dropna(inplace=True)\n",
    "\n",
    "# Resample datasets to daily frequency.\n",
    "inflation = inflation.set_index(\"observation_date\").resample(\"D\").ffill().reset_index()\n",
    "\n",
    "pgdp = pgdp.set_index(\"observation_date\").resample(\"D\").ffill().reset_index()\n",
    "rgdp = rgdp.set_index(\"observation_date\").resample(\"D\").ffill().reset_index()\n",
    "unrate = unrate.set_index(\"observation_date\").resample(\"D\").ffill().reset_index()\n",
    "\n",
    "# The Federal Funds Target Rate (FFTR) is set by the Federal Reserve. \n",
    "# The Fed used to set a single value as the target, but they shifted to setting a range.\n",
    "# Find the midpoint of the range.\n",
    "\n",
    "fftr_midpoint = pd.DataFrame()\n",
    "fftr_midpoint[\"observation_date\"] = fftr_upper[\"observation_date\"] \n",
    "fftr_midpoint[\"Target\"] = fftr_upper[\"DFEDTARU\"] - fftr_lower[\"DFEDTARL\"]\n",
    "\n",
    "# Combine the midpoint with the old FFTR to get a complete FFTR dataset.\n",
    "fftr_old = fftr_old.rename(columns = {\"observation_date\": \"observation_date\", \"DFEDTAR\": \"Target\"})\n",
    "fftr = pd.concat([fftr_old, fftr_midpoint])\n",
    "\n",
    "# Merge the dataframes\n",
    "df = ffer.merge(inflation, on=\"observation_date\", how=\"outer\") \\\n",
    "        .merge(pgdp, on=\"observation_date\", how=\"outer\") \\\n",
    "        .merge(rgdp, on= \"observation_date\", how=\"outer\") \\\n",
    "        .merge(unrate, on=\"observation_date\", how=\"outer\") \\\n",
    "        .merge(fftr, on=\"observation_date\", how=\"outer\")\n",
    "\n",
    "# Set date as an index and rename the columns\n",
    "df = df.set_index(\"observation_date\")\n",
    "df.columns = [\"Federal Funds Rate\", \"Inflation (%)\", \"Potential GDP\", \"GDP\", \"Unemployment\", \"Target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdc3703-58a3-4785-8005-f3ab7de54a86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42faefb6-c907-4023-9a20-5afbffd7a8cc",
   "metadata": {},
   "source": [
    "All datasets were obtained from the Federal Reserve Economic Database (FRED). Links to each dataset are in the reference list at the bottom of the Notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd033e4-c4e6-42b8-bb57-ea64c7169394",
   "metadata": {},
   "source": [
    "We will need to derive some features:\n",
    "\n",
    "Inflation gap: Inflation - Inflation target \n",
    "\n",
    "Output gap: Real GDP - Potential GDP\n",
    "\n",
    "Inflation target is set at 2% by the Federal Reserve and is therefore treated as such our models (Karakas, 2023)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a843232-1712-4f06-abe8-87d4c48c094a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the inflation gap and output gap and add them to the dataframe\n",
    "df[\"Inflation Gap\"] = df[\"Inflation (%)\"] - 2\n",
    "df[\"Output Gap\"] = df[\"GDP\"] - df[\"Potential GDP\"]\n",
    "\n",
    "# Find Inflation Lag and Output Gap Lag for Karakas Model\n",
    "df[\"Inflation Lag\"] = df[\"Inflation (%)\"].shift(1)\n",
    "output_gap_lag = df[\"Output Gap\"].shift(1)\n",
    "\n",
    "# Create a percentage versions of Output Gap Lag and Inflation Lag for Karakas Model\n",
    "df[\"Output Gap Lag %\"] = (output_gap_lag / df[\"Potential GDP\"]) * 100\n",
    "\n",
    "# Drop rows with missing values from table\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Drop Potential GDP and GDP columns as they are not needed\n",
    "df = df.drop([\"Potential GDP\", \"GDP\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf6f05b-eb3d-4d66-a728-4bd3b754312b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "duplicates = df.index.duplicated(keep=False)\n",
    "print(df[duplicates])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fe6423-9383-40ac-a97d-a6be7a39d750",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84ab46e-6035-4a73-a6c6-58edaf93f03d",
   "metadata": {},
   "source": [
    "Karakas (2023) used vectors for the variables and changed the values to percentages. We need to create features to match this so that we can replicate the Karakas Model. We use first lagged variables as our vectors. Since the values of each of our variables can vary in numerical size, we apply Standard Scaling to the variables we will use for modeling to prevent the differences in size from affecting the models and their predictions.\n",
    "\n",
    "We checked for duplicate rows earlier, but there were none. We checked again after merging the data sets. We dealt with missing values from the dataset by removing them completely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0e59f9-5a44-4bf1-ada1-7edd8f5f13c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the percentage of extreme values to cap\n",
    "winsor_limits = (0.05, 0.05)\n",
    "\n",
    "# Apply Winsorization to all numeric columns except the dependent variable\n",
    "for col in df.columns:\n",
    "    if col != \"Federal Funds Rate\":\n",
    "        lower = np.percentile(df[col], winsor_limits[0] * 100)\n",
    "        upper = np.percentile(df[col], 100 - winsor_limits[1] * 100)\n",
    "        df[col] = np.clip(df[col], lower, upper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e127a6-4633-4e9d-afaa-65b32eb7e2bf",
   "metadata": {},
   "source": [
    "Here, we capped extreme values using Winsorization. We set the percentage of extreme values to cap at 5%, which should remove most outliers with massive gaps from the rest of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db35ab5-3083-41c2-bfde-7d017f567f9b",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc751c11-371e-424d-a2b0-2a1099bd2b5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print the first 5 values of the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8670461f-76bf-44cc-9352-0511152c9027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the last 5 values of the dataframe\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81139350-497b-483e-b6fe-865ce68d7c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shape of the dataframe, showing the number of rows (observations) and columns\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8261329-c93a-485c-9487-a72726a439b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the types of each variable\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c8a976-787b-4153-82da-dc07710794d9",
   "metadata": {},
   "source": [
    "The data is entirely in float64, which is a data type that can be used for machine learning models in general."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4862227a-0130-49c8-abc4-7bbf383942d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compute Summary Statistics\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21fbe62-4193-49c0-b5b7-8b6ffd2806fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for column in df.columns:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.lineplot(df[column])\n",
    "    plt.title(f'{column} over time')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c668c76-a7d8-40ea-b66e-96a9ca42618a",
   "metadata": {},
   "source": [
    "The FFR and Target have been steadily decreasing since the 1980s. Inflation, Output Gap, and Unemployment have roughly remained around a constant level over time, despite having some sharp rises or drops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d2e0fb-08f3-4d81-90ef-7342940cfd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a Correlation Heatmap\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.heatmap(\n",
    "    df.corr(),\n",
    "    annot=True,  # Display correlation values\n",
    "    cmap=\"coolwarm\",\n",
    "    fmt=\".2f\",  # Limit to 2 decimal places\n",
    "    linewidths=0.5,\n",
    ")\n",
    "plt.title(\"Correlation Heatmap\", fontsize=16)\n",
    "plt.xticks(rotation=45)  # Rotate x-axis labels for readability\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b25135-edba-493a-8e37-46367e28b2d7",
   "metadata": {},
   "source": [
    "Inflation, Inflation Gap, and Inflation Lag are perfectly correlated to each other, while Output Gap and Output Gap Lag (%) are very strongly correlated, which is expected. We will not be trying any models that use more than 1 in each set as predictors at a time.\n",
    "\n",
    "Unemployment and Output Gap are strongly correlated, so we will need to watch out for these when checking the Variance Inflation Factors (VIFs) for multicollinearity issues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b0801b-1d51-4d54-826c-3762d1056bc8",
   "metadata": {},
   "source": [
    "## OLS Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ce5a05-1ed8-4b75-981c-ddb8c09e8e1b",
   "metadata": {},
   "source": [
    "The variables used for each regression Model are listed as follows:\n",
    "\n",
    "Taylor's Rule Model: \n",
    "\n",
    "    Dependent variable: Federal Funds Rate. \n",
    "    Independent variables: Output Gap, Inflation Gap\n",
    "\n",
    "Karakas Model:\n",
    "\n",
    "    Dependent variable: Federal Funds Rate. \n",
    "    Independent variables: Output Gap Lag %, Inflation Lag (%)\n",
    "    \n",
    "Target Model:\n",
    "\n",
    "    Dependent variable: Federal Funds Rate. \n",
    "    Independent variables: Output Gap, Inflation Gap, Target\n",
    "    \n",
    "Unemployment Model:\n",
    "\n",
    "    Dependent variable: Federal Funds Rate. \n",
    "    Independent variables: Output Gap, Inflation Gap, Unemployment\n",
    "    \n",
    "Both Model (uses both Unemployment and Target):\n",
    "\n",
    "    Dependent variable: Federal Funds Rate. \n",
    "    Independent variables: Output Gap, Inflation Gap, Target, Unemployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa6bb88-a7d3-4f4c-b976-21c3ac85e591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Robust Scaler to independent variables\n",
    "scaler = MinMaxScaler()\n",
    "df_vars = [\"Unemployment\", \"Target\", \"Inflation Gap\", \"Output Gap\", \"Output Gap Lag %\", \"Inflation Lag\"]\n",
    "df[df_vars] = scaler.fit_transform(df[df_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688d64f2-4ffd-42c8-bf39-7276e6a57764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set dependent variable\n",
    "y = df[\"Federal Funds Rate\"]\n",
    "\n",
    "# Define independent variables for each model\n",
    "model_features = {\n",
    "    \"Taylor\": df[[\"Output Gap\", \"Inflation Gap\"]],\n",
    "    \"Karakas\": df[[\"Output Gap Lag %\", \"Inflation Lag\"]],\n",
    "    \"Target\": df[[\"Output Gap\", \"Inflation Gap\", \"Target\"]],\n",
    "    \"Unemployment\": df[[\"Output Gap\", \"Inflation Gap\", \"Unemployment\"]],\n",
    "    \"Both\": df[[\"Output Gap\", \"Inflation Gap\", \"Target\", \"Unemployment\"]],\n",
    "}\n",
    "\n",
    "# Initialize dictionaries to store results\n",
    "ols_fitted_models = {}\n",
    "ols_predictions = {}\n",
    "ols_vif_results = {}\n",
    "ols_error_metrics = {}\n",
    "\n",
    "# Loop to fit, calculate VIFs, Calculate error metrics, and extract model stats for all models\n",
    "for model_name, X in model_features.items():\n",
    "    X = sm.add_constant(X)\n",
    "    \n",
    "    # Fit the model\n",
    "    model, y_pred = fit_ols_model(X, y, model_name)\n",
    "    ols_fitted_models[model_name] = model\n",
    "    ols_predictions[model_name] = y_pred\n",
    "\n",
    "    # Calculate VIF\n",
    "    vif_data = calculate_vif(X, model_name)\n",
    "    ols_vif_results[model_name] = vif_data\n",
    "   \n",
    "    # Calculate error metrics\n",
    "    metrics = error_metrics(y, y_pred)\n",
    "    ols_error_metrics[model_name] = metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c874b009-3439-4c6e-b036-8d5aedc7e1de",
   "metadata": {},
   "source": [
    "### OLS Regression Assumptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0d5ec8-2717-4541-a1ee-17e69dee1348",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Dictionary to store assumption test results\n",
    "ols_assumption_tests = {}\n",
    "ols_residuals = {}\n",
    "\n",
    "# Iterate through models\n",
    "for model_name, model in ols_fitted_models.items():\n",
    "    residuals = model.resid\n",
    "    X = model.model.exog\n",
    "\n",
    "    # Normality Tests (Jarque Bera)\n",
    "    jb_test = jarque_bera(residuals)\n",
    "\n",
    "    # Homoscedasticity Test (Breusch-Pagan)\n",
    "    bp_test = het_breuschpagan(residuals, X)\n",
    "\n",
    "    # Autocorrelation Test (Durbin-Watson)\n",
    "    dw_stat = sm.stats.durbin_watson(residuals)\n",
    "\n",
    "    # Linearity Tests (Rainbow)\n",
    "    rainbow = linear_rainbow(model)\n",
    "\n",
    "    # Store results\n",
    "    ols_assumption_tests[model_name] = {\n",
    "        \"Durbin-Watson Test Statistic\": f\"{dw_stat:.6f}\",\n",
    "        \"Jarque-Bera p-value\": f\"{jb_test[1]:.6f}\",\n",
    "        \"Breusch-Pagan p-value\": f\"{bp_test[1]:.6f}\",\n",
    "        \"Rainbow Test p-value\": f\"{rainbow[1]:.6f}\"\n",
    "    }\n",
    "    \n",
    "# Print results\n",
    "for model, results in ols_assumption_tests.items():\n",
    "    print(f\"\\nAssumption Test Statistics and P-values for {model}:\")\n",
    "    for test, value in results.items():\n",
    "        print(f\"{test}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e30717-163c-4b41-91df-c806da5a670c",
   "metadata": {},
   "source": [
    "The assumptions of regression include:\n",
    "\n",
    "1. Normality of residuals\n",
    "2. Homoscedasticity\n",
    "3. Autocorrelation\n",
    "4. Linearity\n",
    "5. Multicollinearity\n",
    "\n",
    "These assumptions can be tested using the Jarque-Bera test (Normality), Breusch-Pagan test(Homoscedasticity), Durbin-Watson test (Autocorrelation), and Rainbow test (Linearity).\n",
    "For every model, the above p-values are all around 0 and the Durbin Watson test statistic lies between 0 and 0.5. \n",
    "\n",
    "H0: The model does not violate the regression assumption\n",
    "\n",
    "H1: The model does violate the regression assumption\n",
    "\n",
    "Using the 95% confidence level (significance level 0.05), the Jarque-Bera test, Breusch-Pagan test, and Rainbow test statistics all have p-values of around 0, which is less than the significance level. Therefore, we would reject the null hypothesis, H0, that the models do not violate the corresponding regression assumptions. \n",
    "\n",
    "For the Durbin-Watson test, statistics less than 1 or greater than 3 indicate strong autocorrelation and would violate the regression assumption of autocorrelation.\n",
    "\n",
    "The models violates the first 4 regression Assumptions, which makes its results completely unreliable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c989b4-767c-4bce-9e13-83cd6aba7fc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print VIFs for all models\n",
    "for model_name, vif_data in ols_vif_results.items():\n",
    "    print(f\"VIF for {model_name} Model:\")\n",
    "    print(vif_data)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cff406-fe30-430d-a3d3-c8082c450a93",
   "metadata": {},
   "source": [
    "From the VIFs, we do not have serious problems with multicollinearity. There is moderate level of multicollinearity for Output Gap in the Both Model, but it is rather close to 5, which is the threshold for moderate levels and should not cause major issues if left alone. Unemployment, the other variable of interest from our correlation matrix analysis, has acceptable multicollinearity levels. Every other model has VIFs below 5, and mostly around 1. There are no serious issues of multicollinearity, which is the only regression assumption that can be considered passable for the models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c56310-6913-4d6c-92bc-a3cc8070577b",
   "metadata": {},
   "source": [
    "### Taylor and Karakas OLS Model Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc55fed-85f9-4965-b8f5-156ae6242578",
   "metadata": {},
   "source": [
    "While all the regression assumptions except for Multicollinearity were violated and the results are unreliable, we can still compare our visualizations and metrics to Karakas's results and check if we reproduced their regression models, which is one objective of this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8778d6d3-b8a0-4d34-8893-33770d218aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Taylor Model Summary:\\n\")\n",
    "print(ols_fitted_models[\"Taylor\"].summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1cf6cd-9c8c-4a90-8029-89d478c2f6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Karakas Model Summary:\\n\")\n",
    "print(ols_fitted_models[\"Karakas\"].summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b40479-94de-438c-94ff-35d8bb5ae67b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Taylor Predictions vs Actual Plot\n",
    "selected_model = \"Taylor\"\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(df.index, y, label=\"True Federal Funds Rate\", color=\"royalblue\")\n",
    "plt.plot(df.index, ols_predictions[selected_model], label=f\"{selected_model}'s Rule Predictions\", color=\"red\")\n",
    "plt.title(f\"{selected_model}'s Rule Predictions vs Federal Funds Rate\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Federal Funds Rate\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ef2a4b-74f7-4962-a9fc-84ddf5a7928a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Karakas Predictions vs Actual Plot\n",
    "selected_model = \"Karakas\"\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(df.index, y, label=\"True Federal Funds Rate\", color=\"royalblue\")\n",
    "plt.plot(df.index, ols_predictions[selected_model], label=f\"{selected_model}'s Rule Predictions\", color=\"green\")\n",
    "plt.title(f\"{selected_model}'s Rule Predictions vs Federal Funds Rate\")\n",
    "plt.title(\"Karakas vs Federal Funds Rate\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Federal Funds Rate\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f1366a-7382-452a-b135-e6005c6752aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Taylor Predictions vs Karakas Predictions vs Actual Plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(df.index, y, label=\"True Federal Funds Rate\", color=\"royalblue\")\n",
    "plt.plot(df.index, ols_predictions[\"Taylor\"], label=\"Taylor Model Predictions\", color=\"red\")\n",
    "plt.plot(df.index, ols_predictions[\"Karakas\"], label=\"Karakas Model Predictions\", color=\"green\")\n",
    "plt.title(\"Taylor vs Karakas vs Federal Funds Rate\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Federal Funds Rate\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346dd541-0034-46d2-a065-080493ad94de",
   "metadata": {},
   "source": [
    "The plots look similar to the ones shared in Karakas' (2023) paper. The date range is smaller in our plots, since the addition of other variables has restricted our date range due to missing values. However, for the dates that overlap between our plots and the ones Karakas shared in their paper, the plots do match. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a15cc0-c2fe-4b73-9012-ca824dcba452",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Assuming y contains actual values and y_pred contains predicted values\n",
    "RSS_taylor = np.sum((y - ols_predictions[\"Taylor\"]) ** 2)\n",
    "print(f\"Residual Sum of Squares (RSS):\")\n",
    "print(f\"RSS for Taylor: {RSS_taylor:.2f}\")\n",
    "RSS_karakas = np.sum((y - ols_predictions[\"Karakas\"]) ** 2)\n",
    "print(f\"RSS for Karakas: {RSS_karakas:.2f}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# Assuming y contains actual values and y_pred contains predicted values\n",
    "print(f\"Sum of Absolute Errors (SAE):\")\n",
    "SAE_taylor = np.sum(np.abs(y - ols_predictions[\"Taylor\"]))\n",
    "print(f\"SAE for Taylor: {SAE_taylor:.2f}\")\n",
    "SAE_karakas = np.sum(np.abs(y - ols_predictions[\"Karakas\"]))\n",
    "print(f\"SAE for Karakas: {SAE_karakas:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ada4af-cd9f-4e3d-bff7-c46a130195a3",
   "metadata": {},
   "source": [
    "Like Karakas (2023), we found RSS and SAE values were higher for the Karakas Model. Having obtained similar results from the visualizations and metrics, our goal of reproducing the Taylor and Karakas Models has been successfully achieved. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a068695a-78e2-41c5-be4b-6002d4fbae53",
   "metadata": {},
   "source": [
    "### OLS Model Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfb1493-a4c3-4e86-90b8-f32ada42deb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list to store model statistics\n",
    "model_statistics = []\n",
    "\n",
    "# Loop through the fitted models to extract key statistics\n",
    "for model_name, model in ols_fitted_models.items():\n",
    "    # Extract key values\n",
    "    results = {\n",
    "        \"model\": model_name,\n",
    "        \"adj_r_squared\": round(model.rsquared_adj, 3),\n",
    "        \"aic\": round(model.aic, 3),\n",
    "        \"bic\": round(model.bic, 3),\n",
    "        \"f_stat\": round(model.fvalue, 3),\n",
    "        \"f_p_value\": round(model.f_pvalue, 3),\n",
    "        \"t_p_values\": model.pvalues.round(3).tolist(),\n",
    "    }\n",
    "    # Append the results for each model\n",
    "    model_statistics.append(results)\n",
    "\n",
    "# Convert results to a DataFrame\n",
    "statistics = pd.DataFrame(model_statistics)\n",
    "statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e63b8f8-c6ad-4a00-830e-32be2171f2ab",
   "metadata": {},
   "source": [
    "Although the results may be unreliable, we find that the Taylor Model has higher values for R-squared, adjusted R-squared, but lower values for Akaike Information Criterion (AIC), and Bayesian Information Criterion (BIC) compared to the Karakas Model. The AIC and BIC are metrics that measure model quality, while considering complexity (number of features). Generally, the model with lower values for AIC and BIC is better than the model with higher values for them. This is consistent with how the Karakas Model explains less variance than the Taylor Model, as measured by adjusted R-squared.\n",
    "\n",
    "While the results may not be reliable, notice that the inclusion of the Unemployment variable and the Target variable raises R-Squared very greatly. The Target Variable drives up R-Squared the most. Adding Unemployment to the model after including Target (resulting in the Both Model) raises R-Squared but only by a tiny amount. The inclusion of these two variables are still worth exploring in a different model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a5b05c-24fe-468e-aaaf-b1f2c79fc433",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ols_error_metrics_df = pd.DataFrame(ols_error_metrics).T.round(4)\n",
    "ols_error_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cbca1e-9fd7-463e-9c07-8aa0bb39fc03",
   "metadata": {},
   "source": [
    "The error metrics are also in favor of the Taylor Model having better performance over the Karakas Model. Karakas (2023) claimed that their model had more accurate predictions, but not by much, which we've found is not entirely correct. While the Karakas Model had better RSS and SAE values, which does indicate better fitness, other performance metrics show that, overall, the model does not perform as well as the Taylor Model, having larger average errors and percentage errors. The difference, however, is not very big."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b5e95c-045a-4149-9bdd-b01dd68d1ada",
   "metadata": {},
   "source": [
    "## Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac79b742-7957-422d-82f4-c470c01ec775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dictionaries to store results\n",
    "nn_fitted_models = {}\n",
    "nn_predictions = {}\n",
    "nn_error_metrics = {}\n",
    "\n",
    "# Loop to fit, calculate VIFs, Calculate error metrics, and extract model stats for all models\n",
    "for model_name, X in model_features.items():\n",
    "    model, y_pred = fit_nn_model(X, y, model_name)\n",
    "    \n",
    "    nn_fitted_models[model_name] = model\n",
    "    nn_predictions[model_name] = y_pred\n",
    "   \n",
    "    # Calculate error metrics\n",
    "    metrics = error_metrics(y, y_pred)\n",
    "    nn_error_metrics[model_name] = metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4698f5-154d-47ec-a6da-a68aa1415256",
   "metadata": {},
   "source": [
    "### Neural Network Model Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575cffad-1568-4314-b7c0-b890541c30d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nn_error_metrics_df = pd.DataFrame(nn_error_metrics).T.round(4)\n",
    "nn_error_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2641c385-d3de-4bbd-96a8-74ad861b213e",
   "metadata": {},
   "source": [
    "Our models have returned better results across the board for each model. The differences are most apparant for the Taylor and Karakas models which received a 0.2 increase in R-squared. While the increases in R-squared for the Target and Both models are less sizeable, they are rather huge considering the how high they were in the OLS model to begin with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279783af-c4a7-41b5-9e95-8a583540f6eb",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4342816a-f7ea-4b00-8655-81e1e30e686a",
   "metadata": {},
   "source": [
    "Karakas (2023) noted that Taylor's Rule (and their variant) do not predict the FFR well and changed their model to neural networks, getting better predictions by capturing non-linear patterns. We note that while Karakas obtained poor results from both regression models they constructed, since all regression assumptions except for Multicollinearity have been violated, the results of those regressions are unreliable. We noticed that Karakas did not mention regression assumptions in their paper, so we decided to check them as part of the validation process. The results came as a surprise to us as we were not expecting regression assumptions to be violated. \n",
    "\n",
    "Through our findings from this project, we believe we can explain why both of Karakas' regression models had poor predictive performance. None of the independent variables, including but not limited to those used in Karakas' models, have a linear relationship with the FFR, which may be the reason why a non-linear model works better. \n",
    "\n",
    "Karakas (2023) also mentioned their model having predictions closer to the actual FFR, but not by much. However, the error metrics we computed show that it is the Taylor Model, rather than the Karakas Model that has smaller average errors and percentage errors.\n",
    "\n",
    "We have tested (not shown in this notebook) other regression models (Generalized Least Squares and Huber regression) and transformations (Yeo-Johnson, Box-Cox, Log-transformation), but assumptions are still violated. Certain models and transformations may be able to satisfy linearity, but Normality, Homoscedastity, and Autocorrelation all remain problems. We believe that regression models are not well suited for predicting Taylor's Rule. We believe that non-linear models, such as neural networks, future research to predict the FFR should be focus on non-linear models. While the results may not be reliable due to violation of regression assumptions, it is worth noting that the inclusion of the Target and Unemployment variable did improve performance metrics.\n",
    "\n",
    "After we created the neural network models, we found a similar pattern in model performance level: Karakas < Taylor < Unemployment < Target < Both. However, we now have more reliable metrics. While there was better performance from each model compared to the OLS model, we obtained significantly better performance with the inclusion of Unemployment and Target. However, the Target feature had a bigger effect on the model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677774c6-d3d9-4716-9fff-a077097a5d6c",
   "metadata": {},
   "source": [
    "<h2><center>References</center></h2>\n",
    "\n",
    "Board of Governors of the Federal Reserve System (US). (2025). Federal Funds Effective Rate [DFF]. Federal Reserve Bank of St. Louis. https://fred.stlouisfed.org/series/DFF\n",
    "\n",
    "Board of Governors of the Federal Reserve System (US). (2025). Federal Funds Target Rate (DISCONTINUED) [DFEDTAR]. Federal Reserve Bank of St. Louis. https://fred.stlouisfed.org/series/DFEDTAR\n",
    "\n",
    "Board of Governors of the Federal Reserve System (US). (2025). Federal Funds Target Range - Lower Limit [DFEDTARL]. Federal Reserve Bank of St. Louis. https://fred.stlouisfed.org/series/DFEDTARL\n",
    "\n",
    "Board of Governors of the Federal Reserve System (US). (2025). Federal Funds Target Range - Upper Limit [DFEDTARU]. Federal Reserve Bank of St. Louis. https://fred.stlouisfed.org/series/DFEDTARU\n",
    "\n",
    "Karakas, A. D. (2023). Reevaluating the Taylor Rule with Machine Learning. ArXiv.org. https://arxiv.org/abs/2302.08323\n",
    "\n",
    "U.S. Bureau of Economic Analysis. (2025). Real Gross Domestic Product [GDPC1]. Federal Reserve Bank of St. Louis. https://fred.stlouisfed.org/series/GDPC1\n",
    "\n",
    "U.S. Bureau of Labor Statistics. (2025). Consumer Price Index for all urban consumers: All items in U.S. city average [CPIAUCSL]. Federal Reserve Bank of St. Louis. https://fred.stlouisfed.org/series/CPIAUCSL\n",
    "\n",
    "U.S. Bureau of Labor Statistics. (2025). Unemployment Rate [UNRATE]. Federal Reserve Bank of St. Louis. https://fred.stlouisfed.org/series/UNRATE\n",
    "\n",
    "U.S. Congressional Budget Office. (2025). Real Potential Gross Domestic Product [GDPPOT]. Federal Reserve Bank of St. Louis. https://fred.stlouisfed.org/series/GDPPOT"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
